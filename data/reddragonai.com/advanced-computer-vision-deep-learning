<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="../img/tensorflow.svg"/><link rel="preload" as="image" href="../img/pytorch-icon.svg"/><link rel="preload" as="image" href="../img/python-logo-inkscape.svg"/><link rel="preload" as="image" href="../img/training_imgs/certificate-icon.svg"/><link rel="preload" as="image" href="../img/training_imgs/level_2.svg"/><link rel="preload" as="image" href="../img/training_imgs/clock.svg"/><link rel="preload" as="image" href="../img/training_imgs/course_funding_enroll.png"/><link rel="stylesheet" href="../_next/static/css/c9279efc8fbe65c5.css" data-precedence="next"/><link rel="preload" href="../_next/static/chunks/webpack-fbdde187f9fd1a50.js" as="script" fetchPriority="low"/><script src="../_next/static/chunks/fd9d1056-c9f5cfab2eb2f33d.js" async=""></script><script src="../_next/static/chunks/596-fd0d35f230db4162.js" async=""></script><script src="../_next/static/chunks/main-app-3d617632d76638d6.js" async=""></script><title>Red Dragon AI - Deep Learning for Computer Vision Training Singapore</title><meta name="description" content="Looking to train your team in AI, Deep Learning &amp; Computer Vision for your organization? Find out how to do it properly."/><script src="../_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_aaf875"><div><main class="flex-1 "><div><div><main class="flex-1 "><div><div><div class=" min-h-8vh "><div class=" py-6 px-5  flex items-center justify-between max-w-full  mx-auto bg-black"><h1 class="text-lg ml-8 font-semibold text-white cursor-pointer  "><img alt="Red Dragon Logo" loading="lazy" width="200" height="50" decoding="async" data-nimg="1" class=" object-contain" style="color:transparent" srcSet="../_next/image?url=%252Fimg%252FRedDragon_logo_260x39.png&amp;w=256&amp;q=75amp;q../_next/image?url=%252Fimg%252FRedDragon_logo_260x39.png&amp;w=640&amp;q=75p;w=640&amp;q=75 2x" src="../_next/image?url=%252Fimg%252FRedDragon_logo_260x39.png&amp;w=640&amp;q=75"/></h1><div class="flex items-center justify-end space-x-4"><ul class=" xs:hidden md:flex flex-grow-1 flex-shrink-1 p-0 pr-20 gap-12" style="flex-basis:40remm"><li class="relative transition ease-in-out delay-150   hover:-translate-y-1 hover:scale-110 duration-300"><a class="text-[1.25rem]  font-serif font-normal bg-transparent rounded-full text-slate-200 btn" href="../products">Products</a></li><li class="relative transition ease-in-out delay-150   hover:-translate-y-1 hover:scale-110 duration-300"><a class="text-[1.25rem] font-serif font-normal bg-transparent rounded-full text-slate-200 btn " href="../research">Research</a></li><li class="relative transition ease-in-out delay-150   hover:-translate-y-1 hover:scale-110 duration-300"><a class="text-[1.25rem] font-serif font-normal bg-transparent rounded-full text-slate-200 btn" href="../training">Training</a><div class=" absolute bottom-[-20%] left-0 right-0 h-[0.3rem] bg-red-600 z-[1] " style="width:0%"></div></li></ul><div class="sm:block md:hidden  items-center justify-end space-x-4 relative z-50"><button class="text-white self-center mr-12"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 hover:text-gray-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button><div class=" p-5 absolute bg-gray-100 shadow-xl right-0 top-[50px] rounded-xl hidden"><ul class="flex flex-col gap-3"><li class="cursor-pointer px-3 list-none">Products</li><li class="cursor-pointer px-3 list-none">Research</li><li class="cursor-pointer px-3 list-none">Training</li></ul></div></div></div></div></div><section><div class="flex flex-wrap flex-row min-h-[70vh] w-auto bg-[#1C1A17]"><div class="bg-[#1C1A17] min-w-[3rem] flex flex-col flex-nowrap justify-evenly flex-[55] h-auto"><div class="flex flex-col justify-end flex-1 py-0 px-8"><h1 class="text-white pt-4 pr-12 pb-0 pl-8 text-4xl font-serif font-normal">Advanced Computer Vision with Deep Learning</h1></div><div class="flex flex-col justify-start flex-nowrap flex-[2] pt-4 pr-8 pb-0 pl-[5rem]"><h5 class="text-white pt-4 pr-12 pb-0 text-2xl font-serif font-light">This two day workshop is designed to give participants the skills needed to build cutting edge Computer Vision models with Deep Learning.</h5></div></div><div class="flex flex-[45]" style="background:url(../img/training_imgs/callout-image-picture.png);background-repeat:no-repeat;background-size:cover;background-position:right center;clip-path:polygon(16% 0, 100% 0, 100% 100%, 0% 100%)"></div></div></section><section class="bg-[#d3d3d3] h-[10vh]"><div class="flex flex-row flex-wrap justify-start m-auto w-[90%]"><ul class="flex text-2xl flex-row flex-wrap justify-start m-auto w-full"><li class="py-8 pr-4"><a class=" font-serif font-normal text-black no-underline cursor-pointer" href="advanced-computer-vision-deep-learning#course-details">Course Details</a></li><li class="py-8 px-4"><a class=" font-serif font-normal text-black no-underline cursor-pointer" href="advanced-computer-vision-deep-learning#course-content">Content</a></li><li class="py-8 px-4"><a class=" font-serif font-normal text-black no-underline cursor-pointer" href="advanced-computer-vision-deep-learning#duration">Course Duration</a></li></ul></div></section><section><div><div class="flex flex-row flex-wrap justify-start m-auto w-[90%]"><div class="flex-shrink order-1 pb-8 flex-grow-[5]" style="flex-basis:40rem"><div id="course-details"><h2 class="font-normal text-3xl px-0 pb-0 pt-8 font-serif">What You&#x27;ll Learn</h2><div class="flex justify-start items-start "><div class="flex w-[50%]  max-w-[350px]"><ul class="list-inside py-4   list-none"><li class="font-light  p-4 font-serif"> <!-- -->✓<!-- -->  Building networks such as Resnets &amp; Inception Networks</li><li class="font-light  p-4 font-serif"> <!-- -->✓<!-- -->  How to build Segmentation models with UNets</li><li class="font-light  p-4 font-serif"> <!-- -->✓<!-- -->  How facial recognition models and their networks work</li></ul></div><div class="flex w-[50%]  max-w-[350px]"><ul class="list-inside py-4   list-none"><li class="font-light  py-4 px-8 font-serif"> <!-- -->✓<!-- --> How Object Detection Networks work</li><li class="font-light  py-4 px-8 font-serif"> <!-- -->✓<!-- --> Doing Image translation with Pix2Pix Networks</li><li class="font-light  py-4 px-8 font-serif"> <!-- -->✓<!-- --> Using Advanced Image Augmentation strategies</li></ul></div></div></div><div id="course-content"><h2 class="font-normal text-3xl px-0 pb-0 pt-8 font-serif">Course Overview</h2><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">In the second course in the series, we venture beyond the basic skills to delve into advanced usage of Convolutional Neural Networks and modern image network architectures. This journey takes us from old school classification and object detection right up into the future of image segmentation with Meta&#x27;s Segment Anything Model (SAM), a groundbreaking project that democratizes segmentation, allowing for adaptation to specific tasks without additional training. This makes SAM versatile for a broad set of use cases, from underwater photography to cell microscopy.</p><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">As we understand the current state-of-the-art technologies, we will review the history of ImageNet winning models, the impact of Inception, Residual architectures, EfficientNet, and Vision Transformers, and how they enable the field to go beyond hand-engineered models. Alongside these foundational concepts, we will explore the fascinating world of Stable Diffusion, where randomness meets structure, and chaos turns into order through neural networks like VAEs and GANs.</p><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">Our exploration continues with a deep dive into advanced skills and techniques such as object detection with models like the YOLO series, person tracking with Deep Sort, and pixel-level image segmentation with U-Nets and DenseNets. We will also examine top models using Transformers, and the principles of Generative Adversarial Networks (GANs), including how StyleGAN architectures have evolved over time.</p><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">One of the exciting new areas we&#x27;ll touch on is Diffusion Models, guiding random noise into meaningful structures for tasks like image denoising and inpainting. We&#x27;ll also introduce CLIP, and BLIP-2, visual-language pre-training paradigms that bridge the gap between vision and language models, allowing state-of-the-art results for tasks like visual Q&amp;A.</p><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">Participants will have the opportunity to build with tools like Keras/TensorFlow, PyTorch, JAX and TorchVision, which are often used for cutting-edge computer vision research. Hands-on experience will be an essential part of the course, allowing participants to build models and apply new skills to projects in their field.</p><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">The course duration is 3 days, encompassing 28 hours including online sessions. It offers an introduction to PyTorch and TorchVision, advanced classification, objection detection, and the skills to create applications like image search and similarity comparisons.</p><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">Join us in this comprehensive exploration of computer vision&#x27;s newest frontiers, arming yourself with skills to apply in your own area of work. This workshop brings together the past, present, and future of computer vision, offering a thrilling opportunity to learn and grow in this dynamic field.</p><p class="font-light pr-0 pb-0 pt-4 pl-4 text-justify text-[#808080] font-serif">In this course, participants will learn:</p><div><ul class="text-[#808080] mx-4 mb-0 mt-4 pr-0 pb-0 pt-4 pl-12  list-disc"><li class=" leading-6 px-0 pb-0 pt-2">Advanced usage of Convolutional Neural Networks and modern image network architectures</li><li class=" leading-6 px-0 pb-0 pt-2">Understanding and working with the Segment Anything Model (SAM) for versatile image segmentation</li><li class=" leading-6 px-0 pb-0 pt-2">Exploration of Stable Diffusion, where randomness is transformed into meaningful structures</li><li class=" leading-6 px-0 pb-0 pt-2">Techniques for object detection, person tracking, and pixel-level image segmentation with models like YOLO, Deep Sort, U-Nets, and DenseNets</li><li class=" leading-6 px-0 pb-0 pt-2">Examination of Transformers in computer vision and principles of Generative Adversarial Networks (GANs), including StyleGAN architectures</li><li class=" leading-6 px-0 pb-0 pt-2">Introduction to cutting-edge concepts like Diffusion Models and BLIP-2</li><li class=" leading-6 px-0 pb-0 pt-2">Building experience with tools like Keras/TensorFlow, PyTorch, JAX and TorchVision</li><li class=" leading-6 px-0 pb-0 pt-2">Hands-on practice in creating applications for advanced classification, objection detection, image search, and similarity comparisons</li><li class=" leading-6 px-0 pb-0 pt-2">Acquire skills to create applications like image search and similarity comparisons</li><li class=" leading-6 px-0 pb-0 pt-2">To build various types of Deep Learning Computer Vision models</li><li class=" leading-6 px-0 pb-0 pt-2">Learn about image segmentation and classifying at the pixel level with architectures like U-Nets and DenseNets and how they are used in a variety of image segmentation tasks</li><li class=" leading-6 px-0 pb-0 pt-2">Tracking people and objects through videos</li><li class=" leading-6 px-0 pb-0 pt-2">Person Re-identification and object tracking with Deep Sort</li><li class=" leading-6 px-0 pb-0 pt-2">ViT - Vision Transformer</li><li class=" leading-6 px-0 pb-0 pt-2">VLMs such as PaliGemma and Phi-3 Vision</li></ul></div><br/><br/></div></div><div id="duration" style="flex-basis:20rem" class="min-h-[10vh] xs:max-w-full sm:max-w-full md:max-w-[40vw] lg:max-w-[40vw] flex-grow flex-shrink order-2 m-8"><div class="border-black border-solid border-2 p-8" style="border-radius:48px"><h3 class="px-0 pb-0 pt-4 text-red-600 font-semibold text-[1.3em]">Duration</h3><p class="text-[#808080] font-normal leading-6 px-0 pb-0 pt-2 text-justify">3 days live + 7 hours online</p><h3 class="px-0 pb-0 pt-4 text-red-600 font-semibold text-[1.3em]">Pricing</h3><p class="text-[#808080] font-normal leading-6 px-0 pb-0 pt-2 text-justify">$2700 per pax</p><span class="text-sm text-blue-600">* Please contact us for group discounts</span><h3 class="px-0 pb-0 pt-4 text-red-600 font-semibold text-[1.3em]">Prerequisites</h3><p class="text-[#808080] font-normal leading-6 px-0 pb-0 pt-2 text-justify">A solid understanding of Deep Learning</p></div><div class="mr-0 mb-0 ml-2 mt-6"><h5 class="text-base font-semibold">Technologies we teach will include:</h5></div><div class="flex justify-start items-center flex-wrap ml-0 mr-4 mb-4 mt-8 w-auto gap-3"><img class="h-full  w-12  object-contain" src="../img/tensorflow.svg" alt="tensorflow"/><img class="h-full w-12 object-contain" src="../img/pytorch-icon.svg" alt="pytorch"/><img class="h-full w-52  object-contain" src="../img/python-logo-inkscape.svg" alt="python"/></div><div class=" h-[50vh] flex flex-col justify-start font-normal  leading-6 mx-4 mb-0 mt-4 px-0 pb-0 pt-4 text-justify"><div class="flex flex-row items-start justify-start gap-8 font-light h-[10vh] leading-6 mx-4 mb-0 mt-4 p-0 text-left w-auto"><div class="  h-8 w-fit"><img style="filter:invert(14%) sepia(96%) saturate(4387%) hue-rotate(9deg) brightness(99%) contrast(89%)" class="h-8 w-auto" src="../img/training_imgs/certificate-icon.svg" alt="Certificate"/></div><div style="flex:4" class="font-light leading-6 p-0 text-left "><h3 class="text-red-600  px-0 pb-2  ">Certificate</h3><p>Earn a certificate upon completion</p></div></div><div class="flex flex-row items-start justify-start gap-8 font-light h-[10vh] leading-6 mx-4 mb-0 mt-4 p-0 text-left w-auto"><div class="  h-8 w-fit"><img class="h-8 w-auto text-red-600" src="../img/training_imgs/level_2.svg" alt=""/></div><div style="flex:4" class="font-light leading-6 p-0 text-left"><h3 class="text-red-600  px-0 pb-2  ">Training Level</h3><p>Intermediate Level</p></div></div><div class="flex flex-row items-start justify-start gap-8 font-light h-[10vh] leading-6 mx-4 mb-0 mt-4 p-0 text-left w-auto"><div class="  h-8 w-fit"><img class="h-8 w-auto" style="filter:invert(14%) sepia(96%) saturate(4387%) hue-rotate(9deg) brightness(99%) contrast(89%)" src="../img/training_imgs/clock.svg" alt=""/></div><div class="font-light leading-6 p-0 text-left " style="flex:4"><h3 class="text-red-600  px-0 pb-2 ">Time to Complete</h3><p class="text-[#808080] font-light leading-6 p-0 text-left">Approx. 28 hours to complete</p></div></div><div class="transition-opacity delay-300 duration-500 ease-out flex-1   opacity-100"><a target="_blank" class="bg-[#de0800] text-white text-lg rounded-xl touch-manipulation border border-[#de0800] py-2 px-6 hover:scale-110 duration-300 w-fit" href="https://www.dropbox.com/scl/fi/kdpa9ek6alfieabwsta0j/ACV-Brochure_June_2024-edited.pdf?rlkey=fewklb9nquv0iii8bxg67rkxo&amp;dl=1"> Download Brochure </a></div></div></div></div></div></section><section><div class="min-h-[40vh] bg-[#d3d3d3] px-[10%] flex xs:flex-col sm:flex-col lg:flex-row md:flex-row items-center xs:px-12 sm:px-12"><div class="flex"><h3 class="text-4xl px-0 pb-2 pt-4 text-center text-black font-bold ">Why Study Artificial Inteligence?</h3></div><div class="flex flex-col content-center justify-center  md:pl-8 lg:pl-8 "><h4 class="  font-normal text-2xl px-0 pb-2 pt-4 text-left text-black">1. Demand for AI/DL jobs has never been at this all time high.</h4><h4 class="  font-normal text-2xl px-0 pb-2 pt-4 text-left text-black">2. Developers need these skills</h4><h4 class="  font-normal text-2xl px-0 pb-2 pt-4 text-left text-black">3. AI/DL Jobs pay more than standard developer jobs</h4></div></div></section><section><div class="min-h-[50vh] px-[10%] bg-white xs:my-8 sm:my-8 xs:gap-8 sm:gap-8  flex xs:flex-col sm:flex-col md:flex-row lg:flex-row flex-nowrap items-start justify-center"><div style="flex-basis:30%" class="xs:w-full sm:w-full md:w-[10%] lg:w-[10%] flex flex-col justify-start flex-grow flex-shrink py-0 px-8"><div class="flex flex-row justify-center"><img class="h-auto px-0 pb-0 pt-12 w-[10%]" src="../img/training_imgs/course_funding_enroll.png" alt="Comp Screen"/></div><h4 class="text-2xl px-0 pb-2 pt-4 text-center text-black font-bold">Request More Info</h4><p class="text-base px-0 pb-2 pt-4 text-justify">Sign up to receive additional information about this course. Find out what other learners are doing with the skills they gamed, and evaluate if this course is the right fit for you.</p></div><div style="flex-basis:30%" class=" flex flex-col content-center justify-start flex-grow flex-shrink py-0 px-8"><div class="flex flex-row justify-center"><img class="h-auto px-0 pb-0 pt-12 w-[10%]" src="../img/training_imgs/course_funding_enroll.png" alt="Comp Screen"/></div><h4 class="text-2xl px-0 pb-2 pt-4 text-center text-black font-bold">Frequently Asked Questions</h4><p class="text-base px-0 pb-2 pt-4 text-justify">Do I have to log in at a set time? How does the 360-degree assessment work? At this point, you probably have a few questions, and we’ve got answers.</p></div><div style="flex-basis:30%" class="flex flex-col content-center justify-start flex-grow flex-shrink py-0 px-8 hidden"><div class="flex flex-row justify-center"><img class="h-auto px-0 pb-0 pt-12 w-[10%]" src="../img/training_imgs/course_funding_enroll.png" alt="Comp Screen"/></div><h4 class="text-2xl px-0 pb-2 pt-4 text-center text-black font-bold">Funding Eligibility</h4><p class="text-base px-0 pb-2 pt-4 text-justify">Our easy online application is free, and no special documentation is required. All applicants must be at least 18 years of age, proficient in Englisn, and committed to learning and engaging with felow participants throughout the course. We confirm enrollment eligibility within one week of your application.</p></div></div></section><section><div class="bg-[#1C1A17] h-[35vh] flex flex-col justify-evenly"><div style="flex-flow:row wrap;flex-grow:7" class="bg-[#1C1A17] flex justify-around"><div style="flex-basis:20%;flexflow:column nowrap" class="relative flex flex-col px-4 py-8"><h4 class="font-normal text-xl text-white">About RDAI</h4><div class=" absolute bottom-0 top-14  h-px mx-0 mb-0 mt-1 bg-red-600 w-[70%]"></div><ul class="p-4 text-white"><li class="p-2 text-white"><a class="font-light text-white " href="../about">About us</a></li></ul></div><div style="flex-basis:20%;flexflow:column nowrap" class="relative flex px-4 py-8"><h4 class="font-normal text-xl text-white">Coming Soon</h4><div class=" absolute bottom-0 top-14  h-px mx-0 mb-0 mt-1 bg-red-600 w-[70%]"></div></div><div style="flex-basis:20%;flexflow:column nowrap" class="relative flex flex-col px-4 py-8"><h4 class="font-normal text-xl text-white">Links</h4><div class=" absolute bottom-0 top-14  h-px mx-0 mb-0 mt-1 bg-red-600 w-[70%]"></div><ul class="p-4 text-white"><li class="p-2 text-white"><a class="font-light text-white " href="../training">Corporate Trainings</a></li><li class="p-2 text-white"><a class="font-light text-white " href="../training">Public Trainings</a></li></ul></div><div style="flex-basis:20%;flexflow:column nowrap" class="relative flex px-4 py-8"><h4 class="font-normal text-xl text-white">Social</h4><div class=" absolute bottom-0 top-14 h-px mx-0 mb-0 mt-1 bg-red-600 w-[70%]"></div></div></div><div class="bg-black flex-grow py-4 px-12"><h4 class="font-light text-base text-white">2022-2024© All Rights Reserved</h4></div></div></section></div></div></main></div></div></main></div><script src="../_next/static/chunks/webpack-fbdde187f9fd1a50.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/c9279efc8fbe65c5.css\",{\"as\":\"style\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:I{\"id\":7948,\"chunks\":[\"2272:static/chunks/webpack-fbdde187f9fd1a50.js\",\"2971:static/chunks/fd9d1056-c9f5cfab2eb2f33d.js\",\"596:static/chunks/596-fd0d35f230db4162.js\"],\"name\":\"default\",\"async\":false}\n5:I{\"id\":6628,\"chunks\":[\"2272:static/chunks/webpack-fbdde187f9fd1a50.js\",\"2971:static/chunks/fd9d1056-c9f5cfab2eb2f33d.js\",\"596:static/chunks/596-fd0d35f230db4162.js\"],\"name\":\"\",\"async\":false}\n6:I{\"id\":7767,\"chunks\":[\"2272:static/chunks/webpack-fbdde187f9fd1a50.js\",\"2971:static/chunks/fd9d1056-c9f5cfab2eb2f33d."])</script><script>self.__next_f.push([1,"js\",\"596:static/chunks/596-fd0d35f230db4162.js\"],\"name\":\"default\",\"async\":false}\n7:I{\"id\":7920,\"chunks\":[\"2272:static/chunks/webpack-fbdde187f9fd1a50.js\",\"2971:static/chunks/fd9d1056-c9f5cfab2eb2f33d.js\",\"596:static/chunks/596-fd0d35f230db4162.js\"],\"name\":\"default\",\"async\":false}\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c9279efc8fbe65c5.css\",\"precedence\":\"next\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"O8L84BgJBu6UQ72KLFLZ3\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/training/advanced-computer-vision-deep-learning\",\"initialTree\":[\"\",{\"children\":[\"training\",{\"children\":[\"advanced-computer-vision-deep-learning\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialHead\":[false,\"$L4\"],\"globalErrorComponent\":\"$5\",\"children\":[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_aaf875\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"childProp\":{\"current\":[null,\"$L8\",null],\"segment\":\"training\"},\"styles\":[]}]}]}],null]}]]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",null,{\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1 \",\"children\":[\"$\",\"div\",null,{\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"training\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[null,\"$L9\",null],\"segment\":\"advanced-computer-vision-deep-learning\"},\"styles\":[]}]}]}]}]\n"])</script><script>self.__next_f.push([1,"4:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Red Dragon AI - Deep Learning for Computer Vision Training Singapore\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Looking to train your team in AI, Deep Learning \u0026 Computer Vision for your organization? Find out how to do it properly.\"}],[\"$\",\"meta\",\"3\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"b:I{\"id\":4839,\"chunks\":[\"2272:static/chunks/webpack-fbdde187f9fd1a50.js\",\"2971:static/chunks/fd9d1056-c9f5cfab2eb2f33d.js\",\"596:static/chunks/596-fd0d35f230db4162.js\"],\"name\":\"default\",\"async\":false}\nc:I{\"id\":1459,\"chunks\":[\"5162:static/chunks/5162-9686277a7dd930db.js\",\"2145:static/chunks/2145-915fa6c87ad31bd4.js\",\"5932:static/chunks/app/training/advanced-computer-vision-deep-learning/page-327478276c121ce1.js\"],\"name\":\"\",\"async\":false}\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"div\",null,{\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1 \",\"children\":[\"$\",\"div\",null,{\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"training\",\"children\",\"advanced-computer-vision-deep-learning\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$La\",[\"$\",\"$Lb\",null,{\"propsForComponent\":{\"params\":{}},\"Component\":\"$c\"}],null],\"segment\":\"__PAGE__\"},\"styles\":[]}]}]}]}]\n"])</script><script>self.__next_f.push([1,"a:null\n"])</script></body></html>